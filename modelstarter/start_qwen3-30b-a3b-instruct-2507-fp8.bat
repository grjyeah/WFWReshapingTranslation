@echo off
chcp 65001 >nul
cd /d "D:\llama.cpp"

echo.
echo ğŸš€ æ­£åœ¨å¯åŠ¨ Qwen3-30B-A3B MoE æ¨¡å‹ (Q4_K_XL) ...
echo    æ¨¡å‹è·¯å¾„: D:\GGUF\unsloth\Qwen3-30B-A3B-128K-GGUF\Qwen3-30B-A3B-128K-UD-Q4_K_XL.gguf
echo    ç«¯å£: 6008 | ä¸Šä¸‹æ–‡: 8192 | GPU Layers: 49
echo    Prompt Cache: 16384 MiB
echo.

.\llama-server.exe ^
  --model "D:\GGUF\unsloth\Qwen3-30B-A3B-128K-GGUF\Qwen3-30B-A3B-128K-UD-Q4_K_XL.gguf" ^
  --ctx-size 8192 ^
  --n-gpu-layers 49 ^
  --cache-ram 16384 ^
  --threads 12 ^
  --port 6008 ^
  --host 0.0.0.0

if %errorlevel% neq 0 (
    echo.
    echo âŒ æ¨¡å‹å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„æˆ–æ˜¾å­˜ã€‚
    pause
)
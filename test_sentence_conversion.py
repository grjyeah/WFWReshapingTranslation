#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•é€å¥è½¬æ¢åŠŸèƒ½
éªŒè¯æ–°æç¤ºè¯æ˜¯å¦çœŸæ­£åšåˆ°é€å¥è½¬æ¢ï¼Œè€Œä¸æ˜¯æ€»ç»“
"""
import sys
sys.path.insert(0, '/home/aipcuser/pyworkspaces/WFWReshapingTranslation')
from meeting_processor import MeetingTranscriptProcessor

def test_sentence_conversion():
    """æµ‹è¯•é€å¥è½¬æ¢åŠŸèƒ½"""

    # ç®€å•çš„æµ‹è¯•æ–‡æœ¬ï¼ˆåŒ…å«å£è¯­åŒ–å’Œè¯´è¯äººæ ‡è¯†ï¼‰
    test_text = """[ä¸»æŒäºº]ï¼šå¤§å®¶å¥½ï¼Œæ¬¢è¿å‚åŠ ä»Šå¤©çš„ä¼šè®®ã€‚ä»Šå¤©æˆ‘ä»¬ä¸»è¦è®¨è®ºæ•°æ®æ²»ç†çš„ç›¸å…³å·¥ä½œã€‚

[å¼ æ€»]ï¼šé‚£ä¸ªï¼Œæˆ‘ä»¬éœ€è¦å»ºç«‹ä¸€ä¸ªå®Œå–„çš„æ•°æ®æ²»ç†ä½“ç³»ã€‚å°±æ˜¯è¯´ï¼Œæ•°æ®æ²»ç†éå¸¸é‡è¦ï¼Œå¯¹ä¼ä¸šçš„æ•°å­—åŒ–è½¬å‹è‡³å…³é‡è¦ã€‚ç„¶åå‘¢ï¼Œæˆ‘ä»¬è¦é‡è§†è¿™ä¸ªå·¥ä½œã€‚

[æç»ç†]ï¼šå¯¹ï¼Œæˆ‘åŒæ„å¼ æ€»çš„è¯´æ³•ã€‚å•Šï¼Œæˆ‘ä»¬çš„å¹³å°èƒ½å¤Ÿæä¾›æœ‰æ•ˆçš„æ”¯æŒã€‚å…·ä½“æ¥è¯´ï¼Œå¯ä»¥æå‡æ•°æ®è´¨é‡ï¼Œä¼˜åŒ–ç®¡ç†æµç¨‹ã€‚"""

    print("=" * 80)
    print("ğŸ§ª æµ‹è¯•é€å¥è½¬æ¢åŠŸèƒ½")
    print("=" * 80)

    print(f"\nğŸ“ åŸæ–‡ï¼ˆ{len(test_text)}å­—ï¼‰ï¼š")
    print("-" * 80)
    print(test_text)
    print("-" * 80)

    # åˆ›å»ºå¤„ç†å™¨å¹¶æµ‹è¯•
    processor = MeetingTranscriptProcessor()

    print("\nğŸ”„ æ­£åœ¨å¤„ç†...")
    print("-" * 80)

    result = processor.process_transcript(test_text)

    print("\nâœ… å¤„ç†ç»“æœï¼š")
    print("-" * 80)
    print(result)
    print("-" * 80)

    # éªŒè¯ç»“æœ
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
    print(f"   åŸæ–‡é•¿åº¦ï¼š{len(test_text)} å­—")
    print(f"   è¾“å‡ºé•¿åº¦ï¼š{len(result)} å­—")
    print(f"   è¾“å‡ºæ¯”ä¾‹ï¼š{len(result) / len(test_text) * 100:.1f}%")

    # æ£€æŸ¥æ˜¯å¦ç¬¦åˆè¦æ±‚
    print(f"\nğŸ” æ ¼å¼æ£€æŸ¥ï¼š")

    # 1. æ£€æŸ¥æ˜¯å¦ä¿ç•™äº†è¯´è¯äººæ ‡è¯†ï¼ˆæ”¯æŒ [] å’Œ ã€ã€‘ ä¸¤ç§æ ¼å¼ï¼‰
    has_speakers = bool(("ä¸»æŒäºº" in result or "ä¸»æŒäºº]" in result or "ä¸»æŒäººã€‘" in result) and
                       ("å¼ æ€»" in result or "å¼ æ€»]" in result or "å¼ æ€»ã€‘" in result) and
                       ("æç»ç†" in result or "æç»ç†]" in result or "æç»ç†ã€‘" in result))
    print(f"   âœ… ä¿ç•™è¯´è¯äººæ ‡è¯†" if has_speakers else "   âŒ è¯´è¯äººæ ‡è¯†ä¸¢å¤±")

    # 2. æ£€æŸ¥æ˜¯å¦æ˜¯é€å¥è½¬æ¢ï¼ˆä¸æ˜¯æ€»ç»“ï¼‰
    has_summary_keywords = any(keyword in result for keyword in [
        "ä¸»è¦è®¨è®ºäº†", "ä¼šè®®æ€»ç»“", "é‡ç‚¹æåˆ°", "å½’çº³å¦‚ä¸‹",
        "ä¼šè®®è®®é¢˜", "ä¼šè®®å†…å®¹", "ä¸»è¦å†…å®¹åŒ…æ‹¬"
    ])
    print(f"   âœ… æ— æ€»ç»“æ¨¡å¼" if not has_summary_keywords else "   âŒ ä»ç„¶æ˜¯æ€»ç»“æ¨¡å¼")

    # 3. æ£€æŸ¥æ˜¯å¦åˆ é™¤äº†å£è¯­è¯
    has_colloquialism = any(word in result for word in [
        "é‚£ä¸ªï¼Œ", "ç„¶åå‘¢ï¼Œ", "å°±æ˜¯è¯´", "å•Šï¼Œ", "å—¯", "å‘ƒ"
    ])
    print(f"   âœ… å·²åˆ é™¤å£è¯­è¯" if not has_colloquialism else "   âŒ ä»æœ‰å£è¯­è¯")

    # 4. æ£€æŸ¥æ˜¯å¦æœ‰æ€»ç»“æ€§æ ‡é¢˜
    has_summary_titles = any(keyword in result for keyword in [
        "###", "ä¸€ã€", "äºŒã€", "ä¼šè®®ä¸»é¢˜", "è®®é¢˜ä¸€"
    ])
    print(f"   âœ… æ— æ€»ç»“æ€§æ ‡é¢˜" if not has_summary_titles else "   âŒ åŒ…å«æ€»ç»“æ€§æ ‡é¢˜")

    print("\n" + "=" * 80)

    # ä¿å­˜ç»“æœ
    with open("test_sentence_conversion_result.txt", "w", encoding="utf-8") as f:
        f.write("=" * 80 + "\n")
        f.write("åŸæ–‡\n")
        f.write("=" * 80 + "\n")
        f.write(test_text)
        f.write("\n\n")
        f.write("=" * 80 + "\n")
        f.write("é€å¥è½¬æ¢ç»“æœ\n")
        f.write("=" * 80 + "\n")
        f.write(result)
        f.write("\n\n")
        f.write("=" * 80 + "\n")
        f.write(f"åŸæ–‡: {len(test_text)} å­— | è¾“å‡º: {len(result)} å­— ({len(result) / len(test_text) * 100:.1f}%)\n")
        f.write("=" * 80 + "\n")

    print("ğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: test_sentence_conversion_result.txt")
    print("=" * 80)

    # åˆ¤æ–­æµ‹è¯•æ˜¯å¦é€šè¿‡
    if has_speakers and not has_summary_keywords and not has_colloquialism and not has_summary_titles:
        print("\nâœ… æµ‹è¯•é€šè¿‡ï¼é€å¥è½¬æ¢åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        return True
    else:
        print("\nâš ï¸ æµ‹è¯•æœªå®Œå…¨é€šè¿‡ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´")
        return False

if __name__ == "__main__":
    test_sentence_conversion()

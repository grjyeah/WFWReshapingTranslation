【玉长】：您这边能听见我们说话吗？
【主持人】：我先测试一下网络和语音是否正常。听到这里，请确认。
【玉长】：好的，好。
【主持人】：下午四点已到，我们今天下午的数据治理工具交流会议即将开始。非常感谢各位领导同事的参与与支持。
【主持人】：本次会议的主要内容是邀请恩和北京信息技术有限公司进行数据治理及资产管理方面的交流。我们将围绕业务和技术两个方面展开讨论，并探讨日常工作中遇到的一些问题及其解决方案。
【主持人】：接下来，请恩和的技术总监姚俊先生为我们介绍公司的基本情况以及其在数据治理领域的成就与案例应用情况。
【姚俊】：各位领导，大家好！我是来自恩和的姚俊。今天我们将共同探讨数据治理及资产管理的相关内容。
【姚俊】：今天的讨论将分为三部分进行：

第一部分是关于公司的发展历程。自2012年起，我们专注于数据治理领域；至2020年进一步拓展到数据资产管理工作，并在业内积累了丰富的经验，在金融行业中尤其出色。
【姚俊】：我们的主要客户包括交通银行等大型国有商业银行以及光大、民生证券这样的非银金融机构。此外，在其他行业如太平洋保险集团和泰康人寿保险公司也有广泛的应用案例，这些都证明了我们在该领域的专业能力与实力所在。
【姚俊】：在过去三年里，我们成功实施了一系列重要的项目，例如交通银行的数据治理平台建设以及相关咨询业务；还有包括股份制商业银行在内的多个城市信用社的系统改造工程等。特别是在南京银行、江苏银行这样的大型城商行中也取得了显著成果，这些都表明了我们在该领域的持续创新能力和实际应用价值。
【姚俊】：在团队方面，我们拥有一支由200多名专业数据治理工程师组成的高素质队伍，并积累了丰富的实践经验，在行业内享有良好声誉。通过不断努力和完善自身技术体系，确保为客户提供最优质的服务和支持。

【主持人】：我们也有国资背景。公司发展状况良好。
【张总】：接下来主要介绍我们的企业级数据资产平台及其核心功能。这块儿主要包括两个方面：

一是全流程的数据资产管理；二是智能化程度较高的整体数据治理能力，包含丰富的AI功能，覆盖从数据盘点、采集到登记的全生命周期管理过程。此外，我们还提供一个全国产化的数据建模工具，并支持定制开发。简单模型和ERD（实体关系图）与平台对接良好，对数数据计算及数据模型也实现了全生命周期的管理。
【李经理】：我同意张总的说法。我们的平台能够有效地为整体业务提供支持。
【主持人】：先简要介绍一下我们资产管理平台与其他相关平台的关系。从资产平台出发，在数据治理层中涉及原数据标准、主数据需求等模块，对接各产生层的数据仓库或核心系统及业务系统的原始数据。这些原始数据通过采集后进入我们的数据中台进行管理，再上升至数据资产的管理和使用层面。整体架构清晰明确：基础建设层到服务接入层再到应用层；功能上涵盖标准、安全和资产管理等内容。
【张总】：从功能视角来看，平台主要涉及三个层次——数据治理（包括标准）、下层的数据安全管理以及上层的应用层与数据服务对接。此外，我们的模型工具也可以在数据治理中发挥作用。让我打断一下：

我是业务负责人的解读。为什么我们今天讲的是资产管理平台？刚才我们一起看了案例：离近了怕没声音。我再强调一下，在银行领域里，我们只专注于两个场景——一个是数据管控平台（用于IIT部门、数据架构部和数据管理部），另一个是数据资产平台（具体应用场景）。这次会议中提到的需求主要与我们的需求相关。这张图显示的是一个典型的治理工具框架。

【主持人】：各位好，请大家参加今天的会议。我们今天主要讨论数据治理相关工作。
【张总】：我们需要建立一个完善的数据治理体系。数据治理非常重要，对企业的数字化转型至关重要。
【李经理】：我同意张总的见解。我们的平台能够提供有效的支持。
【王博士】：在我们这个中间层里有七大模块。与这次会议相关的可能包括标准质量、原生数据加数据模型以及数据需求等。这些加上其他的数据模型，大约位于四到五个模块的上端；而下端则是数据安全和分类分级的需求。刚才提到满足监管要求的去年年底文件中提及了这五种工具是当前中间层的主要部分，能够满足您现有的需求。
【张总】：无论您的平台现在是以手工方式管控还是以手工方式进行监管合规，通过这些工具可以将现有需求整合起来。我们之所以推出数据资产平台，是因为在过去观察到的情况表明，在上海浦发银行，其数据资产平台至少应达到六点零至七点零的标准，并已经运行了十年之久。
【李经理】：这个资产平台为我们提供了现成的解决方案。我想询问一下，当前的声音是否正常？请靠近一点麦克风。我将直接为您解答有关该问题。
【主持人】：现在能听到我们说话吗？
【王博士】：确实可以听见您的声音，请问您能否确认呢？
【李经理】：是的，我可以清楚地听到您的话。这个资产平台实际上是这次会议的核心场景之一。这次会议强调的是数据资产管理与盘点，通过这种工具实现价值体现。
【张总】：在这一过程中，在我们右手边有用于构建模型的工具。建模工具有两个主要目的：一个是在建立和管理原有管控内容时发挥作用；另一个是当您进行数据架构设计时能将这些整理得井然有序。这是贯穿整个数据治理过程中的重要环节。
【王博士】：刚才提到的基础平台，如果那四百个核心数据加上CR（客户关系）的数据和其他相关整合在一起，那么这个工具就在中间层起到了承上启下的作用。我之前讲过通过资产平台可以检查和了解资产的使用情况，并且在我们的数据管理和架构部门之间实现从源头到最终消费的一体化流程。
【李经理】：到底如何实现这一数据治理平台呢？我的具体数据资产、分类分级以及监管合规要求又将如何体现呢？
【张总】：这张图是我们今天讨论的核心内容。如果有任何疑问，稍后我们再进行详细探讨和交流。
【王博士】：不好意思，请问一下，在这张图表中看到的数据资产管理与应用部分似乎与下面的数据安全板块中的某些框子非常相似。您能否对此作简要说明呢？

【我】：现在让我们来解读一下数据安全的问题。假设一个例子来说，比如在进行数据分类和分级时：


【我】：这是一个解决数据资产问题的手段。
【我】：从业务的角度来看，这是从业务立项角度考虑的一个技术实践。我们可以通过这个过程了解如何应用这些数据资产，并且看到它们具体用在哪里。
【我】：那么，请看这张图吧。也就是说，在这里每个模块代表一个具体的组成部分。如果你将这七个模块与上述的七项功能对应起来：


【我】：实际上，它描述的是在数据安全领域中所涉及的功能内容是什么样的？举个例子来说，分类和分级就是其中的一部分。
【我】：比如，这些模块包括静态脱敏（例如对敏感信息进行加密处理）以及动态脱敏等技术手段。此外，在数据安全方面还包括审计功能：


【我】：它用于确保所有操作都符合合规要求，并记录下来以备审查。然而，上述提到的七个模块只是从功能的角度来看待它们如何实现。
【我】：实际上，这里应该放置的是分类分级、脱敏（静态和动态）、以及相关的安全与审计合规等内容。这可能是我们之前设置时出现了一些错误理解的地方：


【我】：因此，请允许我重新解释这些内容——分类分级、数据脱敏（包括静态和动态两种形式）还有审计合规，这些都是构成数据安全的关键模块。
【我】：明白了？好的，接下来继续讨论下一个部分的内容。技术层面而言，我们目前使用的是 micsql 和 ES 来处理数据持久化问题，并采用微服务架构支持前端开发工作：


【我】：从外部安全性来说，我们的网络隔离措施确保了系统的安全；而内部的安全扫描也符合一般银行的标准。
【我】：在平台特性方面，我们可以将每个模块独立部署。这意味着我们能够灵活地调整和配置各个组件而不影响整体性能或导致相互干扰的问题发生：


【我】：后端处理是异步的，不会对实时交易造成任何负面影响；多租户的支持也确保了不同用户之间的隔离性以及数据安全。
【我】：我们的业务组件可以单独使用，并且整个系统的配置非常灵活。这减少了定制开发的工作量并提高了效率——所有这些都是基于微服务架构实现的：


【我】：我们每个模块都是根据实际需要来设计和构建的，这样便可以根据具体需求进行调整优化。

【主持人】：我们可以抽取需要的模块来单独部署、处理和应用。
【王工】：从我们整体的可配置性来看非常高。现场根据要求可以灵活搭配组件，并自定义字段进行配置，无需额外开发即可快速上线。
【张总】：在流程管理方面，不同银行和客户的业务流程各不相同。我们可以针对整个平台做统一的自定义配置而不需要专门开发新功能。
【李经理】：接下来谈谈各个模块之间的功能关系。数据治理这块涉及数据标准、模型原数据等环节。从建立标准到通过建模引用这些标准，并生成脚本直接应用于库表生成，同时也可以逆向操作从原数据到模型进行匹配和对标招标工作；然后结合质量模块对采集后的原数据进行检核规则校验。
【王工】：在主数管理方面，客户交易主数据等模型梳理后可以与标准做匹配。这是中间核心功能的一部分，并且所有内容都会同步至资产库表结构中完成基础数据的同步；同时，这些标准化模型也需和资产管理模块保持同步更新。
【张总】：安全模块是独立的部分，包括分类分级管理。在标准层进行分类分级的同时也可以针对原数据单独做分类分级处理。
【王工】：接下来谈谈我们的原数据模块。这是最基础的模块之一，首先从采集方面来看，我们有一个适配市面上大多数数据库的采集器，并且曾为交行做过适配；当然具体情况还需视具体情况而定。

【主持人】：大家好。今天我们主要讨论的是关于采集和开发的问题。
【李经理】：我们目前的客户中使用四百产品的较少，例如交通银行这类客户较多。在数据采集上可能需要一些时间。此外，在完成数据采集后，我们会进行全血缘分析、链路分析以及营养分析，并将这些工作体现在血液原数据部分。之后可以与资产模型和标准模型对接。
【张总】：我们现有的数据源非常丰富，包括ETR数据库及各种报表工具等都可以直接连接并采集到系统中。几乎市面上大多数的数据库我们都能够连通并且实现数据采集，这使得开发量相对较少。在Circle部分的数据预解析上，只要符合Circle语法标准，则血缘链路分析准确率可达95%以上。
【李经理】：通过半年左右的时间进行圈匹配后，在员银行领域内的血液关系分析的准确率达到99%以上。对于企业级的溯源和追溯问题，从字段集到数据源都可以实现。在标准化方面，我们支持标准文件的创建、发布以及全流程管理。此外，我们在智能处理上积累了多年经验，并拥有覆盖金融行业的词库。
【张总】：这些词库可以从单词到代码进行标准化处理，在建模时可以直接与我们的标准匹配。可以强制性地将模型落标或根据实际情况对标。我们还可以对原数据与其他系统之间的差异做分析，一旦引用了我们的标准后便能完成冠标的分析工作。在平台中可以看到所有与标准的匹配度以及差异率。
【李经理】：通过这些标准化流程和智能处理技术的应用，我们可以确保数据采集、开发及管理更加高效准确，并且能够满足企业级的需求。

【主持人】：我们可以多体系管理。因为不同的情况，我们企业如果说有多套标准体系的话，可能应对不同监管，会有多套不同的标准体系。
【张经理】：可以在我们的平台里面去建立两套不同或者多套的标准体系。从冠标就是标准的分析能力上，我们整体的一个差异分析；公标的分析这块的整体整个报表也是非常清晰的。词库这块的话我们会有一套金融行业的标准的一套词库，这也是客户用得比较多的部分。
【李经理】：在这一块建立会比较快啊，我们也可以通过在线的方式制作，保证一个标准的一个保鲜。
【张经理】：从模型这块儿的话，那我们模型分成两块。一个是微部端和 b 端。b 端主要是作为一个模型的管理；模型管理这块当然也是可以支持逆向建模、正向建模。在效率上会比客户端稍微差一点。
【张经理】：整体上的话就是从新建模型，不管是正向建模还是逆向建模再到后续的审核发布，都在整体的模型端，模型管管理里面都是可以实现；通过系统的维度或者项目的维度也可以实现。
【李经理】：我们的智能功能和标准是可以做一个智能推荐。在我们建完模之后，可以进行一个对标投标工作，在这块是我们整个 AI 功能的一部分后面有会有一个比较详细的介绍。在建模后生成的 DDR 语句也可以和原数据去做匹配；那数据目录的话可以去落地分析到底多少和我们的原模型是有一样的，哪些是有差异的。
【张经理】：我们有一个 c 端的一个支撑工具，可以直接从标准这块引用已经使用的标准，直接通过正向或者逆向建模建立。然后在正向或逆向建模后与标准匹配；同步生成 DDR 语句到平台去对接之后可以跑脚本。
【李经理】：我们可以通过这些功能实现对原数据的精确分析和高效管理，在整个过程中保证了标准化和智能化，从而提高模型管理和数据分析的整体效率。

【张经理】：那么这样的话可以避免后续建模时出现一些小错误。
【李经理】：在进行匹配标准后，
就可以确保模型符合标准化要求。整体的模型闭环管理涵盖了创建、审核和发布整个生命周期，包括项目管理和配置化工具支持。
【王工程师】：通过平台我们可以在系统中完成所有配置与管理工作。建模工具有丰富的可视化功能，并且能够高效地实现智能标注。
【张经理】：接下来请简要介绍一下主数据部分。重点讨论的是质量控制问题。从整体上，我们可以制定年度质量规划并分解到各个部门的解决方案，
然后生成业务规则和结合科技手段进行实施，在发现问题后进行整理与提升。这是自上而下的方式来实现。
【李经理】：另外一种方法是从具体的问题出发，当在生产或测试环境中发现数据问题时，
我们会从这些问题入手提出改进措施，并通过平台上的报表分析统计出相关指标并评分。这些操作可以按部门和规则分类。
【张经理】：请确认一下，在处理质量问题方面你们是否有追踪模块？如果有这样的系统会自动将需要解决的问题分配给相关人员吗？
【李经理】：我们有一个工单管理系统，从问题的发起直至最终解决问题的过程都在平台上完成，
实现了数据闭环管理。

【主持人】：我们今天讨论的问题是关于数据的解决。闭环处理可以在平台里完成。
【张总】：考核这块很简单。我们的平台能够提供有效的支持。
【李经理】：我想问一下，数据质量是一个独立系统吗？这是平台里的一个独立模块——数据质量模块。
【王主管】：它主要解决的应用场景在哪里呢？
【主持人】：比方说我们集团在系统集成过程中可能需要管控从系统A到系统B的数据。这是我们做数据质量管理的一种方式。
【张总】：那你们这个数据质量的功能模块，主要针对哪些应用场景呢？如果没有具体的场景，我简单说明一下主动提升质量的方式。
【王主管】：我们在监管报送中会有一个预测或客户信息的质量提升计划。我们可以在平台里录入整体的提升计划。比如今年的目标是将问题解决率提高到80%以上，并分配给各个部门实施。
【李经理】：比方说，银行的个人和对公客户的行政计划被分发后，他们可能会根据自己的业务生成相应的规则——个人客户需要检查九要素，而公司客户则需检查三至五个要素。在业务规则制定之后，再由科技人员编写具体的检核规则并执行。
【张总】：这些规则是可以配置的，并且能够支持实时场景操作吗？比如从系统A到系统B的数据传输过程？
【王主管】：是的，在监管报送中我们可以实现这一点。例如，当个人客户信息需要处理时，我们可以通过平台录入提升计划并将任务分配给相关部门执行。
【主持人】：通过这种方式，不仅可以确保数据质量达到预期标准，还能提高业务效率和准确性。

【我】：我可能马上就要做掉。因为从我们平台的角度来看，主要还是这个老师提到的要跟数据平台结合起来。
【老师】：假如你的数据源是四百里的数据，然后你数据平台那边的数据平台我不了解。
【我】：如果用 Rouderer 的话呢？Colrodirea 你原来可能有 CDC（变更数据捕获），你要用它去补货，t 加零 t 加一。
【我】：首先在你的数据平台上，在我们进行数据质量治理的过程中，管你在用哪个平台。
【老师】：对吧？
【我】：然后你们的场景呢？假如说是监管合规的话，这是指的意思。二点零版本。
【老师】：那我们的管理和建设应该某种意义上是你的平台和你的监管数据应用，它是整个数据中台的一个通道。
【我】：那么在 t 加零这个实时阶段内要结合，在你用 flick CDC 的话呢？你要跑出来。
【我】：你跑出来之后再跟 flick CDC 去做集成就可以了。我只是负责这端，把你的业务规则和流程拿出来。
【老师】：就是说你需要把这些规则应用到对应的系统里面去。
【我】：然后那个系统就可以处理相关的数据质量的一些规则了？对吗？
【老师】：是这个意思吧？
【我】：那么弗利斯到海豆的话呢，我就读读你的害我的话就行了。我知道谢谢。
【老师】：嗯，这块还有什么问题吗？
【我】：没有，那我就往后讲了。
【老师】：好的，考核方面简单说一下。我们根据数据治理过程中发现的一些问题可能会对各个部门或一些会有一些考核评分的工作。
【我】：这是考核的内容可以在我们的整体考核模型的考核模块里面去做。
【老师】：i 是没有这个，接下来呢？接下来说一下我们的整体资产这块儿，那资产是个大头。
【我】：从运营角度来看的话主要是像那个资产地图整体的一个资产分布以及资产目录，在资产门户去展现。
【老师】：在个人中心方面我们可能针对每个人对资产的一些互动会在资产的个人中心里面管理。
【我】：然后整体的运营这块，我们的门户包括一些动态统计都会在这块处理。接下来一块就是资产盘点也是一个重点工作。
【老师】：那像从资源化到资产化的这个过程呢？首先我们就先做一个盘点以及确权工作。

【主持人】：那盘点工作的话，在我们的系统里可以实现自动化盘点。可以通过这个系统对一些信息进行补全。
【张总】：另外我们还可以在系统里面完成安全分类分级和打标的工作。同时，业务标签的打标也可以在这个过程中完成。
【李经理】：此外，在资产生命周期管理方面，从盘点到发布、审核再到下线以及后续使用认证等环节都在我们的平台里统一进行管理。
【主持人】：我们之前已经讨论过在数据治理过程中的所有问题，包括原数据和采集过的原始数据。还包括质量规则与标准模型，并将这些同步到资产中去。
【张总】：通过不同类型的数据类型展示补充内容，在资产里面可以看到完整的记录。主要讨论的是数据治理工具和平台的价值所在。
【李经理】：我们目前有一个智慧血缘的工具，它在一些行业中应用得很好。这个工具能够快速地提取测购脚本、数据库原数据，并将它们清晰地显示出来。
【张总】：对于科技部门来说，这有助于进行影响分析等操作，非常方便且直观。简单的元架构展示也与我们资产管理平台一致。底层技术架构是微服务的结构。
【主持人】：从功能特性来看，整体上支持主流 SQL 语句解析。确保解析准确率在百分之九十五以上甚至更高，在有代码和 Circle 的地方都能被解析出来。
【张总】：除非数据非常不规范的情况外，稍作调整后也可以解决。我们还支持算子级语法的解析，并构建全链路的企业级数据水源从源头系统到数仓应用层。
【李经理】：通过这种方式可以实现对整个流程的全面覆盖和管理。

【主持人】：以上就是我们产品的一个介绍。接下来我们说一下后续数据治理能力的简单介绍。
【张总】：我们在数据治理方面有以下几项具体措施和方法论：

在标准层面，我们将提供一套完整的金融行业标准库供公司选择使用。这套标准包含基础数据标准管理，并涵盖企业级数据字典。目前该类数据字典已被广泛应用于银行领域，同时我们还集成了保险业常用的数据字典。
【李经理】：从基础标准的管理来看，我们现在常用的工具是企业级数据字典。这些工具不仅在金融行业广泛应用，在其他行业中也有着广泛的使用率和认可度。张总：我们在构建整体的标准库时会采用闭环式管理模式，即通过数据模型、原生数据以及数据标准三者之间的协同作用来实现标准化管理。与以往的做法不同的是，以前我们是从采集原始数据开始建立字典，然后进行事后管控和比对；而我们现在则是从新建模阶段就引入标准，从而确保在正向建模或逆向建模时都能直接生成符合规范的库表结构。
【张总】：如果采用正向建模的方式，在完成模型构建后，系统会自动生成数据库中的库表结构。这种方式能够保证所有数据的一致性和标准化程度；而如果是通过逆向建模，则需要先对现有的空白结构进行对标落标工作以提升其标准水平，并优化原始架构。
【李经理】：在新建系统的背景下，通常要求进行全面的落标工作，包括但不限于将中文字段类型长度与现有规范完全匹配。而对于存量系统而言，在改造过程中我们更倾向于推荐采用逐项映射的方式来实现标准化目标——即将现有的非标准字段逐一对照至符合标准的数据字典中，并完成相应的转换。
【张总】：以上就是我们在数据治理方面的具体措施和方法论，通过这些手段我们可以有效地提升企业的数字化转型能力。

【张总】：我们需要在平台中保存某些内容。这样我们就能知道哪些字段映射到哪些标准了。通过这种方式能够清晰地对它们进行匹配，并解决同名不同义的一些问题的一部分。从原始数据的角度来看，我们的整体方式是这样的：

有一个原数据知识库存在那里，包括采集数据字典和从各种数据库中收集的数据。这些被采集至我们平台里并进行全面管理，涉及全文搜索、差异分析以及版本管理和血缘链路等各个方面。这一切都依赖于我们的数据管理体系，并且我们推崇以模型为管理抓手的抽象管理模式。在设计阶段，我们在建模时就开始引用标准，在生成DR语句后直接执行到数据库中。这样可以确保原数据的质量。对于现有的系统而言，也可以逆向地将它们导入平台并优化模型。在运维过程中，通过我们的平台进行整体血缘分析也是可能的。最终，这些都与整个数据应用相关联——从设计、开发和测试阶段均融入了我们平台的内容。从质量的角度来看，推动闭环管理方案是从事前防范到事中监控再到事后改善的过程。从事前防范开始，我们可以收集问题并提出流程上的改进建议；在事中的持续性开发或优化过程中进行检查以确保符合标准，在上线后通过规则检查找到可能存在的问题。

【主持人】：我们来讨论如何提升整体数据质量。常见的数据质量管理控制模式通常有三种方式：


【张总】：第一种是年度规划模式。这可能是一个公司级别的计划，在制定一个全面的数据质量提升方案后，分解到各个部门。各部门针对自己的专项领域提出解决方案，并制定业务规则和检查规则。定期进行质量考核。
【李经理】：第二种是专项治理模式。例如在监管报送或预测分析这类特定场景中，需要进行专门的提升工作。这种情况下也是通过平台实现流程化操作来完成目标。
【张总】：第三种是从问题出发的方法。我们首先识别出具体的问题点，并深入分析这些问题背后的原因和影响范围。通过对单一问题的解决逐步推动整个数据面的质量改善，同时也可以在平台上实施相应的管理措施如流程改进等。
【主持人】：接下来谈谈安全分类分级的工作方式。目前常用的做法是遵循“零幺九七号本”这一标准指南（由人民银行发布）。此外，在2024年国家还发布了关于GPT的安全类别的国家标准。这两项内容也是我们平台中的重要组成部分之一。
【张总】：在数据安全管理方面，主要从两个角度着手进行分析和分类标记。第一是在建模阶段时确保所有操作符合既定安全标准，并将相应的字段等级明确标注出来；第二是从源头采集原始数据的过程中利用专门的安全分类工具对数据来源直接打标处理。
【李经理】：展望未来的发展方向上，我们建议更多地采用标准化的方法来实现更高效的数据安全管理。这种方法在行业内已经得到了广泛应用并被认为是非常合适的解决方案之一。

【主持人】：从原数据的角度来看，工作量较大。而且整体上后续的应对监管报送要求时，我们需确保所有原数据均达标。
【张总】：在未来的视角下，建议优先考虑标准层面来构建更加完善的治理体系。这样做不仅有助于提升数据质量，还能为我们的标准化提供更好的支持与帮助。
【李经理】：我同意张总的见解。特别是在安全分类分析方面，可以将各类原始数据和标准进行标记，并根据不同的安全等级实施加密、访问控制等措施。此外，脱敏工具也可以用于具体操作中。
【主持人】：接下来让我们讨论一下关于数据资源及资产的问题。近年来，这一领域成为热点话题之一。我们知道流式数据被视为第五生产力的重要组成部分。从我们的角度来看，在平台内部可以实现有效的整理与管理过程——即通过标准化、规范化处理后形成统一的资源库，并逐步转化为可利用的数据资产。
【张总】：在早期阶段，需要先进行盘点和确权工作；包括评估价值并最终确认其归属关系。我们已经积累了丰富的实践经验，并能够提供相应的模板供参考使用。作为指导性方案的一部分，由公司主导完成整体盘点流程，在此之后还要经过审核优化环节才能正式发布。
【李经理】：在实际操作过程中，从确定范围到明确内容再到制定具体模板，这些步骤至关重要。例如，在公共财务渠道、客户险种等方面进行详细记录时，可以清晰地展示出每个项目的具体情况，并为后续分析奠定基础。
【主持人】：这是关于保险领域的一些简单示例目录，请各位参考一下。通过这样的方式我们可以更好地理解并应用相关概念。

在其他保险公司做的基础数据事例应该与 east 有关联。我们这块，在资产目录建立完成后，
会有二级和三级目录。三级目录将与零幺九七号文进行匹配并挂钩；安全等级会自动分配到我们的目录中。最后，标准或原数据会被挂载至分录目录上。分类完毕后，分级自然随之产生。这是一个资产目录的示例。目前入表也是一个热门话题；入门和复杂入表是需要多方协作处理的事情，
包括咨询公司、律事务所、财会部门以及后续的交易所等机构。在 AI 方面的应用方面：
标准质量资产有AI功能支持；可以自动生成数据标签并智能完成标准化工作。审计过程也能通过智能化手段进行。生成脚本同样可以通过AI工具自动创建，从现有规则中读取信息以自动化生成高质量工作的相关操作。资产的管理包括智能盘点和分类；这些都依赖于平台内的智能化工具实现。智能安全分类分级是常见场景之一，
我就不多说了。在标准方面：
新增标准可由我们的平台自动生成；引用标准也可以自动完成。质量提升方面，我们利用高质数据资产的质量库及规则库根据使用场景生成高质量规则。通过这些措施，在整体上提高数据质量管理；这是厂商大致介绍的内容。接下来，请大家提问或提出其他问题。

【厂商代表】：还有一方面呢，厂商会准备一些工具的界面和功能进行简单演示。大家看看有什么问题吗？
【主持人】：现在听不见，请问能听见我说话吗？听到请回应。
【狱长】：听得见，正在截屏。
【主持人】：好的。请大家看一下基于厂商对这个工具平台的介绍，结合平时工作有没有什么疑问可以提问或咨询一下。
【张总】：提到智能分类分级的能力时，是否使用了大模型？
【厂商代表】：我们在智能分类分级这块确实用到了大模型。
【张总】：请问你们的大模型部署在哪里呢？我们自己的大模型是在这个工具里面自带的吗？
【厂商代表】：是的。我们的大模型被集成在分类分级工具里，作为自带的小型专业度较高的小模型。
【主持人】：具体是什么类型的模型呢？例如参数量是多少？
【厂商代表】：我们在常用的知识库和数据字典上进行训练，并根据这些情况部署到整体订单中去实现推荐功能。这里面包含了一些大模型的工具组件。
【张总】：嗯，好的，请问一下关于四百的问题，你们之前是通过什么方式与交行对接呢？
【厂商代表】：我们之前的对接主要是从他们的 egit 进入 IT 系统的方式进行数据抓取和传输。之后适配时可能会选择更适合的方案。
【张总】：那么如果需要特制的话，具体会采用什么样的形式？是通过 EGIT 抓取还是其他方式呢？
【厂商代表】：我们之前与交行对接时主要使用的是他们的 egit 平台进行数据抓取。之后的具体适配方法我们会根据具体情况来决定。
【张总】：好的，请问业务这边的老师是否对当前的数据治理方案有任何疑问？如果有，可以简单说明一下吗？
【厂商代表】：我们可以在首页登录后向各位展示界面和功能，以便大家更好地了解我们的工具及其使用情况。

【主持人】：我们各个模块都能在首页看到像标准原数据模型。这是一体化的管理过程。数据资产、质量考核和求据这些块的数据都在我们的界面上能看到。
【张经理】：我的意思是，通过这个界面能简简单单地查看一些内容。在标准的板块中，首页就能展示我们整体的标准内容。包括标准引用统计以及所有标准被引用次数等统计信息都能看到。
【李总】：从标准管理这块来说，我们需要对各个体系的标准进行有效管理。例如，在银行系统中的每一个具体标准都在这里显示，并且能够查看到这些引用的详细情况。
【王经理】：在人员个人信息方面，我们也能在这边展示出来。从标准里面看，我们可以维护基础信息、业务属性和相关技术信息等管理工作内容。不过我有一个问题——它的每一项数据上的业务相关性、业务标准和技术管理标准是否能直接在这个页面上显示？还是必须点击进去才能查看详细的内容？
【主持人】：详细的信息是存放在内部的配置中，可以进行编辑和保存后展示在列表上。这是一个默认配置模式。如果内容太长或需要更详细的查看，则可以通过其他方式实现。
【张经理】：对于标准审核这块，在这里会显示我们的审核流程。发布之后的标准版本也在这里列出来供大家使用。包括每个版本的具体信息都能看到，例如技术标准和基础标准的发文情况等都可以维护在此界面中。
【李总】：在标准引用分析方面，我们通过选择引用来查看具体情况。由于数据可能不够全面，在这里可以简单介绍一下我们的标准体系以及它被引用的情况在哪里有具体的应用场景。

【主持人】：在这边可以看出来你哪些标哪些模型引用了。
【标准专家】：我们这个标准都在这边呢可以展示出来。像差异分析的话，
那就是我们就是一个标准的一个标准体系的两个前后的版本的一个体系。差异比对可以在这边来观看，然后落标的检查就是我们的一个标准的引用情况。通过它的一个落标率，就是后续的。
【主持人】：比方说我们某一个系统引用了我们的标准，它的一个落标落标的一个评分的落标率，以及那些一些数据都会在这里展示。像词库这块的话，
那我们就是词库这块，我们会有一套我们专用的一个词库。包括单词用语以及英语块都会在我们这里面去管理啊。像用语单词都单独有管理地方，包括码值也是有单独管理的地方。
【标准专家】：然后配置管理就是一些标准体系的建立，就是一些一些配置项都可以在这里配置。比方说像我们的那个就刚刚说的那个展示那些标准的一些信息内容，都是可以在这边维护的。我这边还想问一个问题，在你标准管理的时候某一个字段或某一个数据项，
对不对？他后面能不能去挂一些系统的截屏图片？
【主持人】：能挂吗？呃，这里管控就是标准的管理是在这里。这里的管理和使用的地方其实是在后面的模型以及原数据块去管去使用的。我明白，因为我们可能会有一种场景啊，比如说我们以前在制定意 st 相关的数据项的数据标准的时候，
我们会对这个数据项它取了哪个权威系统对这个权威系统可能可能会有一个截屏。可那目前我们可能是通过其他一些方式把它管理起来。可以吗？那未来比如说我有这个截屏，我在我对这个数据项能不能就是后面直接挂一个系统图片？
【标准专家】：什么都可以呀？可以的你只要加一个个性化字段，
它类型可能你可以放个图片在里面也是可以加的。是的我们所有字段都是可配置化的。你要加字段都是可以加的。
【主持人】：哦好的行，我这样这个没有问题。嗯啊这块大家各位那个业务老师还有 IT 的那个老师你们看一下你们这边有没有什么问题对于标准模块呃有没有什么问题可以想问的？如果没有的话，
那我们就看一下其他模块啊，我们往后哎主要看一下标准质量元数据对。
【主持人】：标准的质量对模型不看不是模型是跟那个原数据时间来不及了。哦行，那我那我就看原数据。因为原数据跟我们模型是挂钩的这三块使用是挂钩的。

不对标准引用也是在模模型里面的模型大概来讲就行了。嗯，
这个图可能现在它还没有，
我们在原数据这块的话，
通过系统形式系统的条目可以在这边展示出来。我们各个系统。美国系统所属的那个那个原数据都会在右边给它展示来。像采集这块的话，
从任务出发，
一个任务是一个最小的一个单元。我们的任务，
比如先采集 a 系统，
再采集 b 系统，
都是在可以这边来新建整体的任务。作业这块是一个就是我们一个作业可以匹配多个任务。比如我有顺序的，那就是在这边可以新建一个作业去匹配我们的任务。这也可以配置那些周期，
包括运行周期啊什么的，
每分钟或者定时执行，

都可以在这边进行操作。后续的一个作业日志，
只要跑的日志，
都能在平台上看到。直接可以看到我们跑出来的一个结果，
这里能看到的日志。打开就能看到，整体的一个日志，
可以在这里执行，

也可以看到。整体的作业时长怎么都能看得到啊。配置这块的话，
我们可以配置我们的系统以及原数据属性，
有哪些挂载点，在这边去配置它。血缘关系映射，
我们需要采集什么内容？都在这边去做一个配置。原数据版本，
同一个系统的一个原数据版本，

进行比对差异分析，可以在这边来做。在来看到每个版本的一些数据，
在这里可以看到。差异分析的话就是我们针对原数据的差异，
前后版本的差异分析啊，
都可以发起。我们可以比生产和测试也可以比生产与生产，
千个版本类型，
开发跟测试去比，
也可以生产跟测试比这边都执行得到。原数据管理主要是在这里，还是主要是个采集展示为主。那原数据和分类分级的一个关系。我要看一下呃，

原数据分我们分类分级是在资产里面的，
就是在在在在资产里面。我们在块的话，
我刚刚也说了，
平台里所有的采集内容都会同步到我们的这同同步到我们资产里面来。通过一个类型，就能看到所有原数据的一个类型都能在这里看到。

【主持人】：我们讨论的是数据资产的管理问题。通过筛选和分类分级的方式，我们可以更好地管理和利用这些数据。
【张总】：我们需要建立一个完善的数据治理体系。数据治理对于企业的数字化转型至关重要。
【李经理】：我同意张总的见解。我们的平台能够提供有效的支持。
【王工】：在我们现有的平台上，资产的业务分类是通过常用的主题和指标体系来进行管控的。安全方面的分级目前还没有被纳入项目范围中。
【主持人】：那么，请问如何进行资产盘点呢？
【李经理】：我们可以直接配置一个任务来完成这项工作，并且它是一个自动化的流程。知识库会帮助我们实现这一目标，同时我们会记录下相关的盘点日志。
【张总】：在运营方面，我们需要关注动态的统计报表。例如一些点单数和评论数等指标，这些都可以被实时监控到。
【王工】：通过分析评价用户对资产调用度的情况，我们可以了解整体的资产规模以及它们的具体使用情况。如果发现错误或者需要纠错的地方，我们可以在平台上进行修正或提出问题。
【李经理】：当我们在数据资产管理模块中捕捉原生数据时，进一步的操作如分类和分级管理将会在这个部分完成吗？
【张总】：是这样的，在这个过程中，我们的数据资产与数据标准之间有着密切的关系。这些标准本身也是被视为一种资产的一部分。
【王工】：实际上，您的数据标准应该能够直接关联到原始的数据上，并且这三者——即数据资产、数据标准和原生数据之间的关系在设计时应当确保互联互通。
【主持人】：也就是说，在整个过程中，所有的标准、模型质量等内容都会被同步至数据资产模块中。最终目标是实现统一管理统计功能吗？
【张总】：正是如此，在实际应用当中，无论是建模还是其他操作环节都将依赖于这个系统来完成相应的任务。

【主持人】：我们来引用数据标准。在原数据建模时甚至可以在逆向使用我们的原始采集的数据进行逆向建立模型。
【张总】：我们需要建立一个完善的数据治理体系。这非常重要，对企业的数字化转型至关重要。
【李经理】：我同意张总的见解。我们的平台可以提供有效的支持。
【主持人】：首先在质量方面，在首页我们可以看到一些质量提升计划和数量统计。规划层面上我们能够制定整体数据质量管理的规划，并且通过点击详情查看后续解决方案的具体案例，例如一层监管报送的质量整改是我们自己制定的计划。
【张总】：我们在建立之后会发布下去，让相关部门生成一个具体的方案。比如数据质量部将进行整体解决方案。如果要达到目标，我需要做哪些选择？比方说业务规则和监控模板制作等操作流程。
【李经理】：这些过程由科技部门负责设计制定规则并实施具体检核规则的执行情况。例如，从自上而下的视角解决客户问题时，业务部门首先提出解决方案，并对个人客户的九要素进行检查以提升特定要素质量。通过建立相应的业务规则实现这一目标。
【主持人】：在完成这些操作后，科技部门会将结果反馈给相关部门进一步确认和调整。我们希望这样的过程能够确保数据质量和业务需求的一致性与匹配度，从而为企业的数字化转型提供坚实的基础支持。

【主持人】：我们到时候写的 circle 都是在这边来配置的。包括一些问题数据怎么统计，整体全量数据怎么统计，都在这里完成。
【张总】：那这边也能看到哪些解决方案与业务规则挂钩的情况。比如可以新建规则或引用已有部署规则等。
【李经理】：是的，这是一个自上而下的提升过程。我们从发现的问题工单出发来解决问题。例如我发现客户号为空这一问题后，通过这个问题进行后续检查。
【主持人】：我发现了市上的一个客户号为空的情况。然后让对应的科技部门去检查具体原因，并形成解决方案解决该问题。在数据质量提升方面，我们需要制定相应的解决方案并推动业务规则的落实到最终检核规则中。
【张总】：在这边的问题工单详细信息里都能看到这些挂钩关系和相互联系的内容。当然所有的配置都是可以调整的。
【李经理】：我们来看具体的一个检测规则吧。在科技板块，我们可以定制开发 circle 的检核规则，并且这里可以看到日志记录。最后生成的数据报告会是什么样子呢？
【主持人】：先说清楚问题数据处理过程。跑出来 circle 之后会显示一个包含所有信息的问题集和脱敏配置等。
【张总】：在问题师处理过程中，可能需要手动处理或直接在生产环境中运行，并于第二天采集完成后再进行下一步操作。

【主持人】：大家好。我们接下来将讨论质量报告的相关内容。我们的质量报告基于固定的模板进行编制，并涵盖数据治理的各个方面。
【张总】：我们需要建立一个完善的数据治理体系。数据治理对企业的数字化转型至关重要，这一点非常重要。
【李经理】：我同意张总的见解。我们的平台能够提供有效的支持。我们使用的五年方案中包含了一些具体的核规则和业务规则。这些是固定模板的一部分，并可以导入到基础的模板中去。
【主持人】：总体来说，数据治理的对象包括提升计划、解决方案以及问题统计等。工单和其他相关事项都能在报告中显示出来。虽然目前的数据可能并不完整，但大致情况就是这样。
【张总】：我们之前有制定过一些数据标准。例如保单主题和客户收付费关联的主题等等。每个主题下包含许多数据项，并且为这些数据项配置了很多质量规则。
【李经理】：最后我希望看到的是整个主题域的数据质量问题统计。具体来说，我想要了解在某个类型上发现了多少问题以及这些问题的解决率。
【张总】：事实上，我们可以通过新建不同的类别来实现这一点。例如，在一年后回顾时可以查看每个主题下有多少数据项被发现存在质量问題，并且这些数据的质量如何变化。我们可以统计出总共发现了多少质量问题、解决了多少个等信息。
【主持人】：你们能够看到这样的统计报表吗？刚才你给我展示的数据质量报告似乎还有些差异，特别是在问题数据的统计方面。具体来说，在这个问题数据部分可以看到有多少问题是由于特定系统或机构的责任造成的，并且有解决率的信息显示出来。
【张总】：我们可以通过配置工具来调整这些内容。例如更改显示的主题域名称等操作都是可以实现的。也就是说我们在使用过程中可以根据需要进行修改，就像在后面添加新的功能一样方便灵活地应对变化的需求和情况。

【主持人】：我们有一个默认的配置。你后面可以添加其他的内容，直接进行添加即可。
【居安娜】：好的，明白了。这个门户像质量规则这块的内容都是可以直接在页面上配置的，在这里加字段就行。
【李经理】：嗯，这些就是一些系统的配置内容。在这里面我们可以分发数据治理机制，并且可以在写质量和写规则的时候做确认操作。比方说你在分发规则时可以基于机构来分发或者通过某些字段映射去分发，都可以在分发过程中实现。
【主持人】：我们也可以做到自动分发。质量这块就这些了，请大家提出其他疑问。
【居安娜】：各位老师请看这里，你们这边有什么问题吗？我居安娜想咨询一下，在咱们之前与别的公司合作时有没有遇到类似的问题？
【李经理】：嗯，刚才你说的是这样的情况吧——当发现一个数据质量问题的时候需要在这个平台登记，并且建工单跟进。之后会形成一些报告。
【主持人】：那我想问是说同一个问题在不同地方重复登记的情况是否常见？比如在我公司的话，首先我们会通过一审平台解决意识端的问题并按照流程处理；IT人员也会根据公司的系统去记录和解决问题，同时也要在这平台上再次登记以确保跟进。也就是说一件事情分了三个地方重复操作。
【居安娜】：你们有没有遇到过类似别的公司在项目实施过程中出现的保险或预问题呢？
【李经理】：我们在需求方面与其他公司有集成，在这里可以做很多数据类需求和标准相关的质量要求，通过与工单系统对接将相关信息推送到我们这边来展示。这样就可以实现后续操作。
【主持人】：这个我补充一下——在分发机制中，我们可以通过机构或字段映射进行灵活的分发，并且支持自动化的处理流程；同时，在数据质量问题上我们可以统一记录和跟踪，避免重复登记的情况发生。

【主持人】：我们通过数据需求平台模板来解决这个问题。从源头上解决问题。刚才我们在PPT讲解过程中意识到二点零融合的近一点意思。二点零属于事后的一个数据质量管理问题。因为你的数据质量可能发生在平台端，也可能发生在数据应用端。
【李经理】：我的意思是说，在应用端你可能会遇到这些问题。而从数据管理的角度来看，我不知道原来的管控平台是如何进行控制的。通过数据平台对数据仓库和OITP四百等的管控都没有实现有效管理。刚才老师提到这三点问题可能需要从三个不同的视角来解决。
【主持人】：我们需要在需求的视角下把数据管起来，这样就能屏蔽掉你的意思。二点零的应用到你数据平台的管控可以通过一个统一的数据质量管理平台进行集中控制和管理。我认为银行保险行业目前都在面临这个问题。因为正如前面提到的，我们通过这个数据驱动来做的这个质量平台大体上是这种情况。
【主持人】：在做数据治理的时候，在构建数据资产时非常重要啊。刚才讲到的是关于数据质量平台的事前、事中监控问题。而大部分企业现在是在事后才开始关注这个问题，并未做到事前和事中的有效管理。我们当前的质量平台旨在解决从头到尾的全流程。
【主持人】：明白了，谢谢。对于数据质量管理这一块，请其他业务老师如Rose或Clean总检查你们那边是否存在类似的问题；还有浩川总，您是否注意到任何问题？如果都没有问题的话，请再看看其他的功能模块吧，并重点关注模型这块儿。
【李经理】：我刚才提到的是我们刚刚讨论到的模型和标准之间的挂钩。在这个平台上我们可以实现标准化操作。我们需要找到一个数据实体及其属性名来设计我们的模型；然后进行标准推荐，当我们在选择字段后会得到智能推荐功能——这个是基于我们已经建立的标准来进行的。
【李经理】：通过这种方式，这些字段可以与现有的标准相匹配，并且确保它们符合既定的标准应用规则。

【主持人】：它的就是像百分之百的那就是就是他直接就是给你推荐这一个这个字段。那也有。如果有多多个类型，
那么可能有会有多个用，
数据项会和您相关的它会推荐出来多的啊。我还没听懂你说的东西呢，我想问一下你这个模块是数据模型模块吗？对、对、对。最简单的一场景就是说各个 AD 它可能会进行数据建模。那数据建模它是基于端进行建模还是基于客户端进行建模都可以建立界面。比如先给大家演示一下，
再看它的建模过程当中怎么跟我们的标准去联合起来的嘛。你它会有压图吗？像刚才这种，就是客户端会会有压图啊。如果说这个客户端是有图的话呢，它的一个建模其实就是一种表格形式的。是的是的是的，
是以清单这边就是 web 端主要还是一个模型管理为主 server 端嗯就端相当于是一点 serserver。我明白你意思了。对，在这可以做一些那个模型的设计，
但 c 端和我这里是对，不太好装装。对，就在单在这边可以看到那些字段的信息都在这边都都有。嗯嗯，

啊就是简单的就是在新建你可以新建一个个字段在一个实体那边去做也可以去一个逆向逆向建模。我们会原素逆向可以不用建，逆向也可以教。你也能确保我们所有要建立的这些表格字段、模型他们都是经过治理后的字段吧，
强冠标了嘛。对呃，在新建完之后，我刚刚不是有个标准化的一个过程吗？就是在做完之后，

你点标准化的时候就是和我们的标准去做一一个匹配。然后根据我们的落标策略就是在建模的时候，就新建模型时会有一个落标策略等于做标准时候是模型这个动作是标准内容范围。对，
我们在那边可以看到我们是有个策略。比方说我们要落标还是对标是在这边可以选择落标的话就是百分之百所有的字段都要一模一样和标准一样才行。对，

对标的话呢，就是做一个映射啊，其实就是模型的标准这就是模型标准的范围很大。对，在模型的就是我这个我这模型的标准是什么样子的那个标那个标准，
一个配置、一个配置标准化程度。

【主持人】：在后续进行标准化的过程中，我们可以智能推荐哪些与你各字段匹配的标准，并将其推送给您。您可以根据这些标准做出相应的选择。
【张经理】：一旦选择了合适的标准，在使用相关应用时，系统会自动将我们这个实体名和字段长度调整为符合所选标准的规范要求。之后，我们会进行发布制并完成标准化工作流程。
【主持人】：在模型分析方面，我们将重点研究两个版本之间的差异，并通过对比来优化模型性能。此外，落地分析环节中，我们可以查看系统的模型实体化率以及变化情况等细节信息。例如，在冠标率这一指标上，您会发现它被细分为软罐标和硬罐标两种类型。
【张经理】：硬冠标的定义是必须完全一致的。这是因为某些系统产品是由厂商提供的，并且无法进行更改；而所谓的“对标”是指将现有数据与目标标准对齐的过程，“落标”则是指在实际应用中实现这一过程的结果。“冠标率”的计算包含了这两部分，确保两者之间达到百分之百的一致性。
【主持人】：软罐标的含义是通过映射来调整现有的数据格式使其符合新的要求。您是否可以通过配置工具选择合适的选项来进行这项工作呢？
【张经理】：当然可以！在模型标准化的过程中，我们需要明确地定义落标或冠标的指标，并将其作为衡量贯标率的重要依据之一。
【主持人】：那么接下来，请大家关注一下我们在内部管理系统中如何处理不同模块之间的协调问题。另外，在讨论采购相关工具时，我们是否应该考虑引入数据血缘分析这一功能？
【张经理】：确实如此！在原数据管理平台上已经集成了基本的学员信息采集和基础数据分析等功能。这些能力可以为后续开发更多高级特性提供支持。
【主持人】：如果按照上述方案实施的话，在进行模型落地时，是否能够有效地追踪到每个字段的变化路径呢？

平台是刚才好几个模块里面专门会有一个吧？那这两者之间有什么区别吗？在线率比较高的话，在线解析实施率也高。你可以在线进行解析。那些复杂的血缘关系可以在那边查看。目前这个平台上暂时没有布，无法看到这边的血缘情况。这里只能看一个相对简单的大致情况。我想看一下有无相关的案例，学员是否能提供基础外贸部署的实际示例？我得等会儿，因为网络有点卡顿。其实这块可能涉及到数据学员方面的关系。我们想看看是否有相关案例。因为我们可能会有两个较大的场景：

第一个场景是说，在报送端到湖库再到四百系统之间有纵向的数据血缘。当在报送端发现数质量问题时，可以通过数据血缘快速找到中间经过哪些表源端和字段。你们是否能够做到这一点？还有一个横向的场景。比如说一个字段在不同系统间流转：

例如 a 系统用到 b 系统再用到 c 系统之间进行交互。假设业务提出新功能需求，本质上可能涉及某个系统的底层变化。我们能否通过分析跨系统看到这张表和相关字段的变化？也就是关联的哪些表、哪些字段也会发生变化，这块是否能做到？可以做到吗？目前你们是否有实施案例，在做横向血缘关系的实际应用呢？南京银行有血缘吧。他们在在线情况下做了横向访问影响分析。廊坊银行也是在进行类似的尝试。

【主持人】：还有个溯源分析就是你可以追溯到源头到底是这个字段。我知道这是正常的操作吗？影响分析方面，您刚刚提到的中间某一个表的某一个字段去找相关数据血源采集时的情况。
【张总】：web service 能够自动扫描，但我们仍然需要人工一个个去配置。API 接口能自动扫到 web 设备接口等吗？
【主持人】：能自动补货吗？你能够做到这一步吗？这个问了是吧，能自动的是可以的吧。
【张总】：对，但人户可能会校验一下。只要一般是有规范的逻辑性数据能找到的话，他都可以自动扫到。
【主持人】：命名和命名可能还是有相关的。你的 web service 逻辑就是他们要配置吗？有已经配置过的，应该是可以逃出来的吧？
【张总】：嗯，行了，我就其他没什么问题了，继续。现在整体功能主要就这些，在数据治理方面非常关键。
【主持人】：因为我们模型是源头管理的。从设计态开始就要对数据质量进行标准化处理。如果在做逻辑模型和物理模型时先定需求的话……


【张总】：所以数据需求很重要。我刚才通过这个探讨觉得有几项可能是与数据治理相关的，包括我们刚刚提到的那个平台。
【主持人】：就是风控角度的监管合规问题可能你们现有的系统可以解决吧？从数据治理本身的场景来看呢？
【张总】：我们要以场景化的方式进行改造，目前看有的是监管合规二点零。就是在数据质量这块需要做改造，并把事前和事中补进来。
【主持人】：这是通过数据治理平台来解决问题的。还有一个就是现在我们分类分级的数据安全问题对吧？还有刚才为什么讲到数据资产平台呢？
【张总】：我们的数据资产平台涵盖了这些工具，基于这些工具去数产。怎么体现出数据资产呢？其实……刚才我提到的一家定义都不准。
【主持人】：不管保险银行自己定义都不准的。我们把指标、标签、服务和平台做的这些模型表都可能被称为资产。所以这个资产是技术部门与业务门之间的桥梁，假如说以指标为桥梁的话……


【张总】：嗯，行了，我就其他没什么问题了。继续。

【主持人】：那我们如何定义指标呢？指标如何服务于数据资产，并体现其价值？
【张总】：在数据治理平台中，通过这一系列的手段来实现数据资产的价值。从这个角度来看，在做分类分级和建立数据资产目录时，盘点显得尤为重要。
【李经理】：我同意张总的分析，特别是在业务部门的风险控制和数据资产管理方面，这将带来显著价值。
【主持人】：第三个价值就是经营分析。通过经营分析体现数据治理的价值，并且在这一过程中以指标为核心进行管理是关键点之一。
【张总】：我认为在未来三到五年间，在整个泛金融行业要特别重视指标建设，确保原生数据的高质量和标准化处理。
【李经理】：具体而言，在人事、财务、战略及营销分析中都能通过良好的数据治理实现价值提升。这是我在需求解读时得出的观点之一。
【主持人】：再者，通过数据管控部门来整合平台与应用之间的关系显得尤为重要。目前我们认为无论是数仓还是BI的需求，都应该是分离的，并以平台建设和BI应用为主导。
【张总】：但是，在进行一体化管理时未能做到这一点是问题所在。核心在于构建合适的数据架构和模型结构。
【李经理】：在讨论数据架构时，标准定义、建模以及如何对数据资产下定义至关重要。这是我们在OITP（运营信息与技术平台）框架下的基础前提条件之一。
【主持人】：如果这些环节被分离处理，则很难确保原生数据的清晰梳理，并且无法实现标准化的数据需求管理。因此，在OITP中，通过数据治理将所有问题统一解决是必要的步骤。
【张总】：我们目前发现的问题主要集中在数据平台和BI应用以及监管机制上的不足之处，这些都暴露了当前存在的数据管控及治理方面的问题。
【李经理】：无论未来选择哪家工具进行管理，在一体化上都是必须的。我们的建议就是通过数据管理部门提供最基础的数据服务，并结合指标等其他功能来支持业务需求分析等工作。

【主持人】：原来我们这种被动的手工数据服务已经转变为一种资产的数据服务。通过数据资产门户能够体现这一点，这正是我们进行数据治理的价值所在。
【张总】：是的，我从三到五个不同的视角来解决这个问题。首先，通过提供高效的数据服务；其次，借助数据资产目录；再次，利用指标经营分析；还有第四点，通过数据安全分类分级这些场景的应用，才能真正体现出建立数据治理体系的重要性与价值所在。我们的平台能够为这一过程提供有效的支持和保障。
【主持人】：我刚才提到的这四个关键方面包括了什么？它们是如何帮助我们实现目标呢？
【张总】：通过这些方法，我们可以清晰地看到数据治理的价值，并确保其对企业的数字化转型有着至关重要的作用。具体而言，在数据服务、资产目录管理以及指标经营分析的基础上，结合安全分类分级等措施，可以有效提高工作效率并降低风险。
【李经理】：我完全赞同张总的见解。我们的平台已经积累了大量的BI报表和历史数据集，并且这些资源为我们未来的项目提供了坚实的基础。
【主持人】：那么针对我们现有的系统架构，请问你们是否有具体的实施路径呢？
【张总】：确实如此，目前我们已经有了一些监管合规的需求以及相关的安全分类分析工作。此外，在BI报表方面也积累了丰富的经验，无论是Click还是BO工具都已投入使用多年，并且已经建立了大量的历史数据集。
【李经理】：是的，我们在过去几年间投入了大量的精力来构建我们的平台和仓库系统，这使得我们拥有了一套完整而成熟的数据治理体系。然而，我们也意识到，在当前状态下可能存在一些重复加工的情况——例如三千个或五千个指标中存在大量重复信息的问题。这种现象不仅反映了数据质量上的不足之处，也揭示了我们在数据治理过程中存在的问题。
【主持人】：那么请问你们对于如何改进这一状况有什么建议吗？
【张总】：从长远来看，我们需要对现有系统进行标准化处理，并在ETL调度时加入严格的数据质量校验机制。这样做不仅能保证新生成的指标准确无误地存储到数据库中，还能帮助我们更好地管理整个数据资产生命周期。
【李经理】：我同意上述观点。通过实施这些改进措施，我们可以确保未来的项目能够更加高效、可靠地运行，并为公司创造更大的价值。

【主持人】：这是跟平台有关的。刚才提到数据集这块与 BI、业才和人事相关，但不涉及战略。
【张经理】：假如你在数据平台上积累了不同的表，比如 ODS 表、DWD 表、DWS 表以及 ADS 表，并且这些表是你的数据集市表（AADS），那么你可能会面临重复的问题。如果将这些表纳入到一个数据治理平台或资产平台进行管理，则需要确保它们被妥善管理。
【李经理】：如果我们不管理好现有的数据，就无法解决当前问题。现在有两个关键点需要注意：一是现有数据平台本身存在问题；二是目前的数据集存在准确性不足的情况。刚才提到如何解决问题时，我认为必须采取被动措施来应对现状。我们应该以应用为导向进行解决方案的设计，并通过数据集推动数据平台的改进以及 OATP 的优化。
【王博士】：从源头上解决这些问题并不现实，因为要彻底改变现有的核心系统可能非常困难甚至不可能实现。因此，我们建议应该先从数据应用和现有数据平台入手解决问题，逐步向后端的数据源推进。这是我们目前的最佳实践方案之一。
【张经理】：根据统计数据显示，在中国的一些大型银行中（例如建设银行或股份制商业银行），这些机构通常拥有超过200个至300个不同的小规模数据库系统；而较小的金融机构可能只有不到100个数据集，但这种情况已经持续了近25年。然而，这并不是针对 OITP 这一部分进行的数据管理。
【李经理】：如果我们不解决源头上的问题（如 OIAP 数据源），那么无论我们如何努力完善数据标准和需求定义，在业务系统中始终无法保证准确性。最终导致的问题是即使在 ODS 中存储的信息仍然是错误的。因此，我认为应该更加重视通过数据治理来改善整体的数据质量和管理流程。
【主持人】：从图示来看，可以清晰地看到数据源、平台与应用之间的关系；这三者之间存在着紧密联系，并且为用户提供了一个有效的工具支持机制。老师，请您确认我是否理解得正确？感谢您的耐心聆听！

【张总】：那这样的话就是说如果这种情况成立的话。因为我们有一些系统是产品，也就是说是从外部购买来的。
【李经理】：如果是这样子的话，他们可能遇到的困难会比较大吧？
【王工】：在这种情况下一般怎么处理呢？通常来说：


【王工】：首先需要进行数据架构的设计和规划。假设你们公司的核心系统原来是全球性的，并且使用了某种叫 AAKKG 的美国产品。
【张总】：对，那你的整个核心系统的范围包括 RATP 这块，改动起来会很困难吧？
【李经理】：没错，在这种情况下如果你不建立新一代的核心系统的话。那么直接从原来的四百层数据导入到 ODS 数据库中去，是吗？
【王工】：确实如此。也就是说在 ODS 中的数据是从其他地方采过来的。
【张总】：如果我们只考虑结构化数据的情况，就认为这些 ODS 的数据已经符合标准了，对吧？那么基于这些 ODS 的数据进行后续的工作：


【李经理】：如果 ODS 数据本身不符合标准的话。那在做数据质量、安全和分类分析时就会存在很大的隐患。
【张总】：确实如此，这是一些深层次的问题。只能一个一个地解决它们了。
【王工】：目前在国内的银行已经进行了颠覆性的改革，在新一代核心系统建设过程中：


【李经理】：他们并没有动用 TP 和 AP 的资源，而是同时推进数据治理、标准和模型的工作，并最终完成新系统的构建。
【张总】：而国内保险公司在这方面做得比较差。坦白说，这说明了为什么数据治理的价值在于它是一个持续的过程。
【王工】：我们倡导的数据治理永远在路上，因为只有这样才可能实现真正意义上的进步。如果在 TP 方面不做改进的话：


【李经理】：即使你在 AP 面上做再多努力也都是徒劳的，在 ODS 层面上依然会存在断层问题。
【张总】：那么有没有针对这种情况的具体实施方案呢？我们有银行的一些案例可以参考，但具体到我们的公司还需要进一步探讨和制定方案。

【主持人】：刚才我们这几天主要接触的是上海交通银行的数据源。这是来自AI四百的解决方案，在过去三年里为其提供数据治理相关方案。
【张总】：在POC阶段时，我们将详细分享我们的案例，例如类似交行的案例。
【李经理】：我同意张总的分析，平台能有效支持相关的数据工作。
【主持人】：各位老师，请检查是否有其他问题。如果有需要讨论的问题请随时提出。Jeff总，您这边有疑问吗？
【Jeff总】：我们听不到声音。麦克风是否打开？没有听到任何声音。
【主持人】：确实没听见声音。屏幕显示也没有声音信号。
【张总】：江福通，请问你能听到GF那边的声音吗？我看到你的麦克风是打开的，但还是无法听到你说话。
【Jeff总】：我的麦克风已开启，听不到的话可能是问题出在设备上。
【主持人】：我们再试一次。请确认您的麦克风是否正常工作，并检查是否有其他干扰因素影响声音传输。
【张总】：薛老师，请您这边看一下业务团队有没有遇到什么数据管理方面的问题或建议？
【薛经理】：我们在日常工作中使用了一些工具，但没有针对具体问题的解决方案。
【主持人】：也就是说你们希望我们提供的这个工具平台能够解决这些问题吗？请明确一下您的需求。比如在采购这样的工具时，您希望它能帮助您实现哪些目标呢？
【张总】：首先，请确认这是对我们公司整体数据治理的一个重要支持工具，并非仅针对某个部门。
【薛经理】：我们需要一个能够提前发现并解决问题的平台，在报送端进行规则校验。这将减轻我们在事后处理问题的压力，提升工作效率和质量。
【主持人】：感谢您的反馈！

【发言人】：当然我还想看看比如说业务在其他方面，


【发言人】：看看有没有什么很好的建议啊，
或者问题需要这边的厂商来帮你们解答、沟通交流。
【发言人】：这样我可以说说，因为我们其实目前主要是一些报表。我们的报表其实都已经开发了，
我不知道这个怎么解决这个问题。有些报表呢，
其实都是 IT 帮我们开发的。首先能不能做到，
我们自己就可以提设定值，
设范围自己去取数就是可以的。
【发言人】：当然这个数是看在哪里取啊，
我刚才说意 st 的原因是因为意 st 已经把所有业务数据拆分到非常细的一个维度了。如果再去报表，对我们来讲其实是没啥意思的。我为什么要这么说？举个例子：
你去菜场买排骨肋排，
总是一根先称好再切碎。
【发言人】：切碎以后，
很难回到原来的数据。其实也一样。业务数据，
一张保单的数据，
分得越细，
还原程度就越难。如果纯粹是为伊斯特的，换句话说，
他要的是监管那些东西，


【发言人】：如果说这个还有不同的维度，
因为取值的地方不一样啊，
那我们报表维度就是不同。
【发言人】：另外的角度来看，
当然从数据库来说，
数据来源肯定也就不一样了。刚才我提到的意思是说：
某种意义上讲，数据治理为平台手段，它只是监管合规的要求。比如它是监管部或者风控部，


【发言人】：这是他们做的一个数据集。刚才我也说了，
大都会保险至少有几十个甚至上百个数据集啊，
这些数据集其实都有质量问题。
【发言人】：从指标的角度来说，
我非常熟悉 BI、指标到数仓和这个数据集成，已经做了二十多年了。不管是做经营分析还是精准营销，


【发言人】：在交叉销售方面，
对各种场景的看都是需要关注的数据集或场景。

【主持人】：让我们继续讨论标签和画像的问题。你发现你现在想要的数据必须准确，对吧？我的基本数据要准；第二个我怎么增值呢？或者怎么通过这个标签画像来获客并留住客户？
【李经理】：这些公司肯定在做标签和画像的工作。从BI的角度来看，自助分析是经营险团险指标的重要组成部分。
【张总】：你提到的现有东西可能是被动的对吧？我去进行自助分析或查看固定报表；通过点击查询或使用BO工具来获取信息已经足够了，但我怎么实现动态操作呢？
【李经理】：刚才我们讨论到AI的到来。我如何智能问数、智能查看？这些都是在业务经营和分析中体验出来的。
【张总】：作为数据治理的后台手段，它是解决数据治理体系中的问题的重要工具。这个平台赋能给BI指标；对于与我们治理相关的，假如说从经营分析的角度来看就是指标的话，那么现有的指标一定会存在同名异义或不同名称的问题。
【李经理】：例如财务和营销部门对同一个销售额可能有不同的定义，这就需要我们的数据治理体系重新定义这些指标。作为资产和服务于经营分析的指标来说，这确实是一个很好的数据治理手段和应用场景。
【张总】：对于经营分析而言，BI展现就是通过数据分析进行展示的过程；把指标这个数据集当成一个data service，然后提供给BI门户进行展现。
【李经理】：从运营和分析的角度来看，在我们使用工具的过程中可能遇到的问题是指标。我们的工具可能是你们之间的桥梁或通道，解决这个问题是我们迫切需要的解决方案之一。
【张总】：事实上，我们在大都会的数据项可分为两种类型：一种为基础数据项；另一种为指标类数据项。对于这些指标链来说，我们需要解决的是各部门对同一个指标口径统一、数据一致的问题，但在具体维度上可能会有差异。

【主持人】：那么在你的产品里面，你们的指标类数据项与基础数据项之间会有关系吗？因为我们现在分析下来是说，几指标类数据项是由基础若干个基础数据项合并而来的。你们是这么做的吗？
【张总】：我们确实是从这样的角度来设计和实施我们的方案。在你的数仓中，DWD 和 DWS 的汇总与明细操作定义了这些指标的构成元素。
【李经理】：那么你是在数据平台里边通过 DWD 和 DWS 汇总明细的时候，把数仓中的这些指这些东西都先定义好了吗？
【主持人】：是的。在你的现有系统中，数仓和增量数据总是处于动态变化之中。如果缺乏一个统一的数据体系，我们就无法确保这些指标、明细数据以及汇总结果的历史准确性。
【张总】：因此，在我们构建和完善这一框架时，必须从数据平台的角度出发，建立一个统一的指标体系，并提供相应的工具支持。
【李经理】：那么如果我们有了这个统一的指标体系和数仓，再结合 BI 平台的数据集，就可以实现全面、高效的业务分析与决策了。不过，在我们现有的系统中是否已经具备这样的能力呢？
【主持人】：当前情况下，虽然我们可以从数据平台提取出相应的表结构和指标定义信息（包括原子指标、派生指标以及衍生指标），但这些工具更多地是被动响应需求。
【张总】：如果我们能够建立一个统一的指标体系，并将其与数仓紧密结合，则在 BI 工具中就可以实现更高效的业务分析。这正是我们数据治理工具和平台的核心价值所在，它不仅管理了数据标准化工作以及汇总操作，还确保所有相关方都能从这些平台上获得准确、一致的信息。
【李经理】：那么，在这个统一的指标体系下，是否可以将原子指标、派生指标及衍生指标等定义得更加清晰明确呢？这将有助于我们更好地利用 BI 工具进行业务分析和决策支持。

【主持人】：关于你提到的数据平台数据应用的问题。现有的东西大多是历史的，并不是动态的。
【张经理】：通过数据治理工具可以解决数仓是动态的问题。无论是叫“实时数仓”还是“动态数仓”，我们都要解决实时数仓，统一指标体系和 BI 现有的问题。具体来说，假设我看到你工具里面前面有指标的数据项，并且有一个专门的管理页面。
【张经理】：如果我点进一个指标，可以清楚地看到它涉及到哪些基础数据项，并能够进行连接关联操作。然而，我的意思是说你现在所有的数据集和指标中存在同名不同名、同一名不同的问题。从数据平台的角度来看，在工具层面我们还没有解决这个问题。
【张经理】：如果你现在改变不了这些数据集，那么我们就只能被动地管理你的数据集。无论是经营分析还是财务或人事的数据，很多指标都是重复的，并且在名称上存在差异。如何解决这些问题？我们认为在建立数据平台时应该对指标体系进行梳理和定义。
【张经理】：通过这样的过程，我们可以在工具层面实现更高效的管理和应用。否则的话，我们的管理将非常被动。还有一件事情我想请教一下。我们可以看到这个工具主要是针对系统结构化数据的管理问题，在监管方面确实看到了一些非结构化的案例。
【张经理】：希望金融机构能够在未来关注和管控非结构化数据。对于目前来说，我们所做的主要还是在结构化数据上的工作。实际上，从数据治理的角度来看，我们需要探索更多关于非结构化数据的需求场景——例如客服或者知识图谱管理等方面的问题都在不断被提出。
【张经理】：总的来说，在现有情况下，我们的工具还主要是针对结构化的管理方式。好的，请各位老师看看还有没有其他问题需要讨论？如果没有的话……

【主持人】：我们本次会议已结束。感谢各位老师的参与与支持。
【老师甲】：非常感谢大家的交流和分享。
【老师乙】：谢谢，再见！
【老师丙】：拜拜！
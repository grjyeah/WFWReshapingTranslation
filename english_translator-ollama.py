import requests
import json
import re
import os
import glob
from typing import List
from difflib import SequenceMatcher
import xml.etree.ElementTree as ET


class EnglishTranslator:
    """ä¸­æ–‡ä¼šè®®çºªè¦ç¿»è¯‘æˆè‹±æ–‡"""

    def __init__(self, ollama_url: str = "http://localhost:11434",
                 # model_name: str = "yasserrmd/Qwen2.5-7B-Instruct-1M:latest"):
                 model_name: str = "did100/qwen2.5-32B-Instruct-Q4_K_M:latest"):
                 # model_name: str = "alibayram/Qwen3-30B-A3B-Instruct-2507:latest"),
                 prompt_xml_path: str = None):
        self.ollama_url = ollama_url
        self.model_name = model_name
        self.api_endpoint = f"{ollama_url}/api/generate"

        # ä»XMLæ–‡ä»¶åŠ è½½æç¤ºè¯
        if prompt_xml_path is None:
            # é»˜è®¤è·¯å¾„
            current_dir = os.path.dirname(os.path.abspath(__file__))
            prompt_xml_path = os.path.join(current_dir, "formatted_prompt_templates", "english_translator_prompt.xml")

        self.translation_prompt = self._load_prompt_from_xml(prompt_xml_path)

        # æ¨¡å‹å‚æ•°é…ç½®ï¼ˆä¼˜åŒ–ä¸ºç²¾ç®€ä¹¦é¢åŒ–è¾“å‡ºï¼‰
        self.model_options = {
            "mirostat": 2,
            "mirostat_tau": 3.5,  # ä¸­ â†’ è‹±ç¿»è¯‘ / ä¸­è‹±æ··åˆè¾“å‡ºï¼Œé™ä½éšæœºæ€§ï¼Œæå‡æœ¯è¯­ä¸€è‡´æ€§ä¸è¯­æ³•æ­£ç¡®æ€§
            "mirostat_eta": 0.1,
            "repeat_penalty": 1.1,
            "num_thread": 8,  # GPU offload åï¼ŒCPU åªéœ€å¤„ç†å‰©ä½™å±‚ï¼Œ8 çº¿ç¨‹è¶³å¤Ÿ
            "num_batch": 512,  # é»˜è®¤å³å¯ï¼Œæˆ–è®¾ä¸º 1024 æå‡åå
            "rope_frequency_base": 1000000,  # Qwen é•¿æ–‡æœ¬é€‚é…

            "num_ctx": 131072,  # ä¸Šä¸‹æ–‡çª—å£å¤§å°
            "num_predict": 8192,  # é™åˆ¶æœ€å¤§è¾“å‡ºï¼Œé˜²æ­¢è¿‡åº¦å†—é•¿
            "temperature": 0.5,  # é™ä½æ¸©åº¦ï¼Œä½¿è¾“å‡ºæ›´ç®€æ´è§„èŒƒ
            "top_p": 0.85,  # é™ä½top-pï¼Œå‡å°‘å‘æ•£
            "top_k": 30,  # é™ä½top-kï¼Œæ›´èšç„¦
            "repeat_penalty": 1.15,  # æé«˜é‡å¤æƒ©ç½šï¼Œé¿å…å•°å—¦
            "presence_penalty": 0.2,  # æé«˜å­˜åœ¨æƒ©ç½š
            "frequency_penalty": 0.2,  # æé«˜é¢‘ç‡æƒ©ç½š
            "stop": ["\n\n\n", "============", "End of", "ã€ç»“æŸã€‘"]  # æ·»åŠ åœæ­¢è¯
        }

    def _load_prompt_from_xml(self, xml_path: str) -> str:
        """
        ä»XMLæ–‡ä»¶åŠ è½½æç¤ºè¯æ¨¡æ¿

        Args:
            xml_path: XMLæ–‡ä»¶è·¯å¾„

        Returns:
            æç¤ºè¯å­—ç¬¦ä¸²
        """
        try:
            tree = ET.parse(xml_path)
            root = tree.getroot()

            # å°†XMLè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œä¿ç•™CDATAå’Œç»“æ„
            import xml.dom.minidom as minidom

            # ä½¿ç”¨minidomæ¥ä¿æŒæ ¼å¼
            dom = minidom.parse(xml_path)
            prompt_str = dom.documentElement.toxml()

            # åªä¿ç•™instructionséƒ¨åˆ†çš„å†…å®¹
            instructions_elem = root.find('.//instructions')
            if instructions_elem is not None:
                # å°†XMLå…ƒç´ è½¬å›å­—ç¬¦ä¸²æ ¼å¼
                prompt_str = ET.tostring(instructions_elem, encoding='unicode', method='xml')
                # å»é™¤XMLå£°æ˜
                prompt_str = prompt_str.replace('<?xml version="1.0" encoding="UTF-8"?>', '').strip()
                return prompt_str
            else:
                raise ValueError("XMLæ–‡ä»¶ä¸­æœªæ‰¾åˆ°instructionså…ƒç´ ")

        except FileNotFoundError:
            raise FileNotFoundError(
                f"æ‰¾ä¸åˆ°æç¤ºè¯æ¨¡æ¿æ–‡ä»¶: {xml_path}\n"
                f"è¯·ç¡®ä¿ formatted_prompt_templates/english_translator_prompt.xml æ–‡ä»¶å­˜åœ¨"
            )
        except Exception as e:
            raise Exception(f"åŠ è½½æç¤ºè¯æ¨¡æ¿å‡ºé”™: {e}")

    def split_text(self, text: str, max_chars: int = 1500) -> List[str]:
        """
        å°†é•¿æ–‡æœ¬æŒ‰æ®µè½æ™ºèƒ½åˆ†å‰²ï¼Œç¡®ä¿åœ¨å¥å­è¾¹ç•Œåˆ‡åˆ†

        Args:
            text: åŸå§‹æ–‡æœ¬
            max_chars: æ¯æ®µæœ€å¤§å­—ç¬¦æ•°

        Returns:
            åˆ†å‰²åçš„æ–‡æœ¬ç‰‡æ®µåˆ—è¡¨
        """
        # æŒ‰è¯´è¯äººå’Œå¥å­åˆ†å‰²ï¼Œä¿æŒè¯­ä¹‰å®Œæ•´æ€§
        speaker_pattern = r'\[([^\]]+)\]ï¼š'
        sentence_endings = r'[ã€‚ï¼ï¼Ÿï¼›â€¦\n]+'

        # å…ˆæå–æ‰€æœ‰è¯´è¯äººæ®µè½
        speaker_blocks = []
        current_speaker = None
        current_content = []

        lines = text.split('\n')
        for line in lines:
            speaker_match = re.match(speaker_pattern, line)
            if speaker_match:
                # ä¿å­˜å‰ä¸€ä¸ªè¯´è¯äººçš„å†…å®¹
                if current_speaker and current_content:
                    content = ''.join(current_content).strip()
                    if content:
                        speaker_blocks.append(f"[{current_speaker}]ï¼š{content}")
                # å¼€å§‹æ–°çš„è¯´è¯äºº
                current_speaker = speaker_match.group(1)
                current_content = [line[len(speaker_match.group(0)):]]
            elif current_speaker:
                current_content.append(line)

        # ä¿å­˜æœ€åä¸€ä¸ªè¯´è¯äºº
        if current_speaker and current_content:
            content = ''.join(current_content).strip()
            if content:
                speaker_blocks.append(f"[{current_speaker}]ï¼š{content}")

        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°è¯´è¯äººæ ¼å¼ï¼ŒæŒ‰å¥å­åˆ†å‰²
        if not speaker_blocks:
            sentences = re.split(f'({sentence_endings})', text)
            chunks = []
            current_chunk = ""

            for i in range(0, len(sentences), 2):
                sentence = sentences[i]
                # æ·»åŠ æ ‡ç‚¹ç¬¦å·
                if i + 1 < len(sentences):
                    sentence += sentences[i + 1]

                if len(current_chunk) + len(sentence) <= max_chars:
                    current_chunk += sentence
                else:
                    if current_chunk.strip():
                        chunks.append(current_chunk.strip())
                    current_chunk = sentence

            if current_chunk.strip():
                chunks.append(current_chunk.strip())
            return chunks if chunks else [text]

        # æŒ‰è¯´è¯äººå—ç»„åˆæˆchunks
        chunks = []
        current_chunk = ""

        for block in speaker_blocks:
            if len(current_chunk) + len(block) <= max_chars:
                current_chunk += ("\n\n" if current_chunk else "") + block
            else:
                if current_chunk.strip():
                    chunks.append(current_chunk.strip())
                current_chunk = block

        if current_chunk.strip():
            chunks.append(current_chunk.strip())

        return chunks if chunks else [text]

    def detect_repetition(self, text: str, window_size: int = 100) -> bool:
        """
        æ£€æµ‹æ–‡æœ¬æ˜¯å¦å‡ºç°é‡å¤å¾ªç¯

        Args:
            text: å¾…æ£€æµ‹çš„æ–‡æœ¬
            window_size: æ£€æµ‹çª—å£å¤§å°

        Returns:
            True if repetition detected
        """
        if len(text) < window_size * 2:
            return False

        # æ£€æŸ¥æœ€åwindow_sizeä¸ªå­—ç¬¦æ˜¯å¦åœ¨å‰é¢å‡ºç°è¿‡
        tail = text[-window_size:]

        # åœ¨æœ€å500ä¸ªå­—ç¬¦ä¸­æŸ¥æ‰¾é‡å¤
        search_range = text[-500:-window_size] if len(text) > 500 else text[:-window_size]

        if tail in search_range:
            return True

        return False

    def call_ollama(self, prompt: str, max_retries: int = 2, use_stream: bool = True) -> str:
        """
        è°ƒç”¨æœ¬åœ°Ollamaæ¨¡å‹ï¼Œæ”¯æŒæµå¼è¾“å‡ºå’Œé‡è¯•æœºåˆ¶

        Args:
            prompt: è¾“å…¥æç¤ºè¯
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            use_stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡ºï¼ˆé»˜è®¤Trueï¼Œé˜²æ­¢å¡æ­»ï¼‰

        Returns:
            æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬
        """
        payload = {
            "model": self.model_name,
            "prompt": prompt,
            "stream": use_stream,
            "options": self.model_options,
            "num_gpu_layers": 60  # æ ¹æ®ä½ çš„GPUæ˜¾å­˜è°ƒæ•´æ•°å€¼
        }

        for attempt in range(max_retries + 1):
            try:
                if use_stream:
                    # ä½¿ç”¨æµå¼è¾“å‡ºï¼Œå®æ—¶ç›‘æ§ç”Ÿæˆè¿›åº¦
                    return self._stream_response(payload, attempt)
                else:
                    # éæµå¼æ¨¡å¼
                    response = requests.post(
                        self.api_endpoint,
                        json=payload,
                        timeout=180  # 3åˆ†é’Ÿè¶…æ—¶
                    )
                    response.raise_for_status()

                    result = response.json()
                    response_text = result.get('response', '').strip()

                    if response_text:
                        return response_text
                    elif attempt < max_retries:
                        print(f"  ç¬¬{attempt + 1}æ¬¡å°è¯•è¿”å›ç©ºç»“æœï¼Œé‡è¯•ä¸­...")
                    else:
                        return ""

            except requests.exceptions.Timeout as err:
                if attempt < max_retries:
                    print(f"\n  â±ï¸ ç¬¬{attempt + 1}æ¬¡å°è¯•è¶…æ—¶ï¼ˆ3åˆ†é’Ÿï¼‰ï¼Œé‡è¯•ä¸­...")
                else:
                    print(f"\n  âŒ APIè°ƒç”¨è¶…æ—¶: {err}")
                    return ""

            except requests.exceptions.RequestException as err:
                if attempt < max_retries:
                    print(f"\n  ğŸ”„ ç¬¬{attempt + 1}æ¬¡å°è¯•å‡ºé”™: {err}ï¼Œé‡è¯•ä¸­...")
                else:
                    print(f"\n  âŒ APIè°ƒç”¨é”™è¯¯: {err}")
                    return ""

        return ""

    def _stream_response(self, payload: dict, attempt: int) -> str:
        """
        æµå¼å“åº”å¤„ç†ï¼Œæ™ºèƒ½æ£€æµ‹é‡å¤å¹¶åœæ­¢

        Args:
            payload: è¯·æ±‚payload
            attempt: å½“å‰å°è¯•æ¬¡æ•°

        Returns:
            æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬
        """
        import time

        response_text = ""
        last_output_time = time.time()
        no_output_count = 0
        max_no_output_intervals = 3  # æœ€å¤šå®¹å¿3æ¬¡30ç§’æ— è¾“å‡º
        check_interval = 30  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡æ˜¯å¦æœ‰æ–°è¾“å‡º

        # é‡å¤æ£€æµ‹ç›¸å…³
        repetition_check_interval = 500  # æ¯ç”Ÿæˆ500å­—ç¬¦æ£€æŸ¥ä¸€æ¬¡é‡å¤
        last_check_length = 0

        try:
            response = requests.post(
                self.api_endpoint,
                json=payload,
                stream=True,
                timeout=180  # è¿æ¥è¶…æ—¶3åˆ†é’Ÿ
            )
            response.raise_for_status()

            print(" [ç”Ÿæˆä¸­", end="", flush=True)

            for line in response.iter_lines():
                if line:
                    try:
                        data = json.loads(line)
                        if 'response' in data:
                            response_text += data['response']
                            last_output_time = time.time()
                            no_output_count = 0

                            # æ¯1000ä¸ªå­—ç¬¦æ˜¾ç¤ºä¸€ä¸ªç‚¹
                            if len(response_text) % 1000 < 50:
                                print(".", end="", flush=True)

                        # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                        if data.get('done', False):
                            print("] ", end="", flush=True)
                            break

                        # å®šæœŸæ£€æŸ¥æ˜¯å¦æœ‰æ–°è¾“å‡º
                        current_time = time.time()
                        if current_time - last_output_time > check_interval:
                            no_output_count += 1
                            print(f"[{no_output_count}Ã—æ— è¾“å‡º]", end="", flush=True)

                            if no_output_count >= max_no_output_intervals:
                                print(f"\n  âš ï¸ æ£€æµ‹åˆ°æ¨¡å‹åœæ»ï¼ˆ{max_no_output_intervals * check_interval}ç§’æ— è¾“å‡ºï¼‰")
                                print(f"  ğŸ“Š å·²ç”Ÿæˆ {len(response_text)} å­—ç¬¦ï¼Œå¼ºåˆ¶åœæ­¢")
                                break

                            last_output_time = current_time

                        # æ™ºèƒ½é‡å¤æ£€æµ‹ï¼šæ¯ç”Ÿæˆä¸€å®šå­—ç¬¦åæ£€æŸ¥
                        if len(response_text) - last_check_length >= repetition_check_interval:
                            if self.detect_repetition(response_text):
                                print(f"\n  ğŸ”„ æ£€æµ‹åˆ°å†…å®¹é‡å¤ï¼Œè‡ªåŠ¨åœæ­¢")
                                print(f"  ğŸ“Š å·²ç”Ÿæˆ {len(response_text)} å­—ç¬¦")
                                break
                            last_check_length = len(response_text)

                    except json.JSONDecodeError:
                        continue

            # æ¸…ç†è¾“å‡º
            response_text = response_text.strip()
            if not response_text and attempt < 2:
                print(f"\n  âš ï¸ ç¬¬{attempt + 1}æ¬¡æµå¼è¯·æ±‚è¿”å›ç©ºç»“æœï¼Œé‡è¯•ä¸­...")
                return ""
            elif not response_text:
                print(f"\n  âŒ å¤šæ¬¡é‡è¯•ä»è¿”å›ç©ºç»“æœ")
                return ""

            return response_text

        except requests.exceptions.Timeout:
            print(f"\n  â±ï¸ æµå¼è¯·æ±‚è¶…æ—¶")
            return ""
        except Exception as e:
            print(f"\n  âŒ æµå¼å¤„ç†å‡ºé”™: {e}")
            return ""

    def translate_to_english(self, chinese_text: str) -> str:
        """
        å°†ä¸­æ–‡ä¼šè®®çºªè¦ç¿»è¯‘æˆè‹±æ–‡

        Args:
            chinese_text: ä¸­æ–‡ä¼šè®®çºªè¦

        Returns:
            è‹±æ–‡ç¿»è¯‘
        """
        print(f"\n{'=' * 60}")
        print("æ­¥éª¤2: ç¿»è¯‘æˆè‹±æ–‡")
        print(f"{'=' * 60}")

        # åˆ†å‰²æ–‡æœ¬ï¼ˆä½¿ç”¨è¾ƒå°çš„ç‰‡æ®µä»¥ä¿æŒç¿»è¯‘è´¨é‡ï¼‰
        chunks = self.split_text(chinese_text, max_chars=1500)
        print(f"æ–‡æœ¬å·²åˆ†å‰²æˆ {len(chunks)} ä¸ªç‰‡æ®µ (æ¯æ®µçº¦1500å­—ç¬¦)")

        translated_chunks = []
        total_output_length = 0

        for i, chunk in enumerate(chunks, 1):
            print(f"[{i}/{len(chunks)}] ç¿»è¯‘ä¸­... (è¾“å…¥: {len(chunk)} å­—ç¬¦)", end=" ")

            # æ„å»ºç¿»è¯‘æç¤ºè¯
            prompt = self.translation_prompt.format(text=chunk)

            # è°ƒç”¨æ¨¡å‹
            result = self.call_ollama(prompt)

            if result:
                translated_chunks.append(result)
                total_output_length += len(result)
                ratio = len(result) / len(chunk) * 100
                print(f"âœ“ è¾“å‡º: {len(result)} å­—ç¬¦ ({ratio:.1f}%)")
            else:
                print(f"âœ— ç¿»è¯‘å¤±è´¥")
                # ç¿»è¯‘å¤±è´¥æ—¶ä¿ç•™åŸæ–‡ï¼ˆè™½ç„¶ä¸ç†æƒ³ï¼Œä½†ä¸ä¼šä¸¢å¤±å†…å®¹ï¼‰
                translated_chunks.append(chunk)
                total_output_length += len(chunk)

        # åˆå¹¶æ‰€æœ‰ç¿»è¯‘ç‰‡æ®µ
        translated_text = "\n\n".join(translated_chunks)

        # è¾“å‡ºç»Ÿè®¡
        print(f"\nç¿»è¯‘ç»Ÿè®¡:")
        print(f"  ä¸­æ–‡è¾“å…¥: {len(chinese_text)} å­—ç¬¦")
        print(f"  è‹±æ–‡è¾“å‡º: {total_output_length} å­—ç¬¦")

        return translated_text

    def _generate_timestamped_filename(self, base_name: str) -> str:
        """
        ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å

        Args:
            base_name: åŸºç¡€æ–‡ä»¶åï¼ˆå¦‚ "english_translation.txt"ï¼‰

        Returns:
            å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶åï¼ˆå¦‚ "english_translation_20251225_143020.txt"ï¼‰
        """
        from datetime import datetime

        # è·å–å½“å‰æ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # åˆ†ç¦»æ–‡ä»¶åå’Œæ‰©å±•å
        if '.' in base_name:
            name, ext = base_name.rsplit('.', 1)
            return f"{name}_{timestamp}.{ext}"
        else:
            return f"{base_name}_{timestamp}"

    def find_latest_processed_chinese(self, input_dir: str = "processed") -> str:
        """
        æŸ¥æ‰¾æœ€æ–°çš„ processed_chinese_<timestamp>.txt æ–‡ä»¶

        Args:
            input_dir: è¾“å…¥ç›®å½•è·¯å¾„

        Returns:
            æœ€æ–°æ–‡ä»¶çš„å®Œæ•´è·¯å¾„

        Raises:
            FileNotFoundError: å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶
        """
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if not os.path.exists(input_dir):
            raise FileNotFoundError(f"ç›®å½•ä¸å­˜åœ¨: {input_dir}")

        # æŸ¥æ‰¾æ‰€æœ‰ processed_chinese_*.txt æ–‡ä»¶
        pattern = os.path.join(input_dir, "processed_chinese_*.txt")
        files = glob.glob(pattern)

        if not files:
            raise FileNotFoundError(
                f"åœ¨ {input_dir} ç›®å½•ä¸­æœªæ‰¾åˆ° processed_chinese_<timestamp>.txt æ–‡ä»¶\n"
                f"è¯·å…ˆè¿è¡Œ python chinese_formatter.py ç”Ÿæˆä¸­æ–‡ä¹¦é¢åŒ–æ–‡ä»¶"
            )

        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„æ–‡ä»¶
        latest_file = max(files, key=os.path.getmtime)

        return latest_file


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–ç¿»è¯‘å™¨
    translator = EnglishTranslator(
        ollama_url="http://localhost:11434",
        model_name="yasserrmd/Qwen2.5-7B-Instruct-1M:latest"
    )

    try:
        # è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„ processed_chinese æ–‡ä»¶
        print("æŸ¥æ‰¾æœ€æ–°çš„ processed_chinese æ–‡ä»¶...")
        chinese_filepath = translator.find_latest_processed_chinese("processed")

        print(f"æ‰¾åˆ°æ–‡ä»¶: {chinese_filepath}")

        # è¯»å–ä¸­æ–‡æ–‡æœ¬
        with open(chinese_filepath, "r", encoding="utf-8") as f:
            chinese_text = f.read()

        print(f"ä¸­æ–‡æ–‡æœ¬é•¿åº¦: {len(chinese_text)} å­—ç¬¦")

        # ç¿»è¯‘æˆè‹±æ–‡
        english_translation = translator.translate_to_english(chinese_text)

        # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
        english_filename = translator._generate_timestamped_filename("english_translation.txt")
        english_filepath = f"processed/{english_filename}"

        # ç¡®ä¿processedæ–‡ä»¶å¤¹å­˜åœ¨
        os.makedirs("processed", exist_ok=True)

        # ä¿å­˜ç»“æœ
        with open(english_filepath, "w", encoding="utf-8") as f:
            f.write(english_translation)

        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print(f"\n{'=' * 60}")
        print("è‹±æ–‡ç¿»è¯‘å®Œæˆï¼ç»Ÿè®¡ä¿¡æ¯ï¼š")
        print(f"{'=' * 60}")
        print(f"ä¸­æ–‡è¾“å…¥: {len(chinese_text)} å­—ç¬¦")
        print(f"è‹±æ–‡è¾“å‡º: {len(english_translation)} å­—ç¬¦")
        print(f"\nè¾“å‡ºæ–‡ä»¶å·²ä¿å­˜åˆ°:")
        print(f"  {english_filepath}")

    except FileNotFoundError as e:
        print(f"\né”™è¯¯: {e}")
        print("\nè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œ:")
        print("1. ç¡®ä¿ input_scripts/meeting_transcript.txt æ–‡ä»¶å­˜åœ¨")
        print("2. è¿è¡Œ python chinese_formatter.py ç”Ÿæˆä¸­æ–‡ä¹¦é¢åŒ–æ–‡ä»¶")
        print("3. å†è¿è¡Œ python english_translator.py è¿›è¡Œè‹±æ–‡ç¿»è¯‘")

    except Exception as e:
        print(f"\nå¤„ç†å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
